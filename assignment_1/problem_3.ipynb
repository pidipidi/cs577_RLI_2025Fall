{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pidipidi/cs577_RLI/blob/master/assignment_1/problem_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3 - Real-world robot demonstrations using a Baxter robot"
      ],
      "metadata": {
        "id": "DrbsbN3TtXmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is an implementation of **Dynamic Movement Primitives (DMPs)** within a `robomimic` simulation environment. The implementation is built on top of the [robomimic tutorial](https://colab.research.google.com/drive/1b62r_km9pP40fKF0cBdpdTO2P_2eIbC6?usp=sharing)."
      ],
      "metadata": {
        "id": "EmWWVXavaayi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "zDYI5it2g2tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WS_DIR = \"/content/\"\n",
        "%cd $WS_DIR\n",
        "\n",
        "# Clone the repo and install the basic requirements\n",
        "!git clone --branch v0.4 https://github.com/ARISE-Initiative/robomimic\n",
        "!pip install -e robomimic/ > /dev/null\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('./robomimic/')"
      ],
      "metadata": {
        "id": "Mnow1rHWiSSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install all system dependencies for mujoco-py\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt install curl git libgl1-mesa-dev libgl1-mesa-glx libglew-dev \\\n",
        "         libosmesa6-dev software-properties-common net-tools unzip vim \\\n",
        "         virtualenv wget xpra xserver-xorg-dev libglfw3-dev patchelf > /dev/null\n",
        "\n",
        "#install mujoco-py\n",
        "!pip install mujoco==3.3.0 > /dev/null\n",
        "\n",
        "#install robosuite\n",
        "!pip install robosuite > /dev/null"
      ],
      "metadata": {
        "id": "KuRFU8Acansp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mujoco\n",
        "\n",
        "mujoco.__version__"
      ],
      "metadata": {
        "id": "jiDbMPcfd-lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import all utility functions\n",
        "import os\n",
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import robomimic\n",
        "import robomimic.utils.obs_utils as ObsUtils\n",
        "import robomimic.utils.torch_utils as TorchUtils\n",
        "import robomimic.utils.test_utils as TestUtils\n",
        "import robomimic.utils.file_utils as FileUtils\n",
        "import robomimic.utils.train_utils as TrainUtils\n",
        "from robomimic.utils.dataset import SequenceDataset\n",
        "\n",
        "from robomimic.config import config_factory\n",
        "from robomimic.algo import algo_factory\n",
        "\n",
        "# for rendering mujoco in colab, you need turn on egl\n",
        "os.environ['MUJOCO_GL'] = 'osmesa' # if gpu possible, use 'egl', if not, use 'osmesa'\n",
        "\n",
        "# the dataset registry can be found at robomimic/__init__.py\n",
        "from robomimic import DATASET_REGISTRY, HF_REPO_ID\n",
        "\n",
        "# set download folder and make it\n",
        "download_folder = WS_DIR + \"robomimic_data/\"\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "# download the dataset\n",
        "task = \"lift\"\n",
        "dataset_type = \"ph\"\n",
        "hdf5_type = \"low_dim\"\n",
        "FileUtils.download_file_from_hf(\n",
        "    repo_id=HF_REPO_ID,\n",
        "    filename=DATASET_REGISTRY[task][dataset_type][hdf5_type][\"url\"],\n",
        "    download_dir=download_folder,\n",
        ")\n",
        "\n",
        "# enforce that the dataset exists\n",
        "dataset_path = os.path.join(download_folder, \"low_dim_v15.hdf5\")\n",
        "assert os.path.exists(dataset_path)"
      ],
      "metadata": {
        "id": "qrO8-vUYeA4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import robomimic.utils.env_utils as EnvUtils\n",
        "from robosuite import load_composite_controller_config, load_part_controller_config, make\n",
        "from robosuite.environments.robot_env import RobotEnv\n",
        "from robosuite.models.tasks import Task\n",
        "from robosuite.models.arenas.empty_arena import EmptyArena\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Free(RobotEnv):\n",
        "    def __init__(self, robots, controller_configs):\n",
        "        super().__init__(robots=robots, controller_configs=controller_configs)\n",
        "\n",
        "    @property\n",
        "    def _visualizations(self):\n",
        "        \"\"\"\n",
        "        Visualization keywords for this environment\n",
        "\n",
        "        Returns:\n",
        "            set: All components that can be individually visualized for this environment\n",
        "        \"\"\"\n",
        "        vis_set = super()._visualizations\n",
        "        vis_set.add(\"grippers\")\n",
        "        return vis_set\n",
        "\n",
        "    def reward(self, action):\n",
        "        return 0\n",
        "\n",
        "    def _load_model(self):\n",
        "        super()._load_model()\n",
        "\n",
        "        self.robots[0].robot_model.set_base_xpos([-1, 0, 0])\n",
        "\n",
        "        mujoco_arena = EmptyArena()\n",
        "        mujoco_arena.set_origin([0, 0, 0])\n",
        "\n",
        "        self.model = Task(\n",
        "            mujoco_arena = mujoco_arena,\n",
        "            mujoco_robots = [robot.robot_model for robot in self.robots],\n",
        "        )\n",
        "\n",
        "    def _check_robot_configuration(self, robots):\n",
        "        pass\n",
        "\n",
        "custom_part_config1 = load_part_controller_config(default_controller = \"JOINT_POSITION\")\n",
        "custom_part_config1[\"input_type\"] = \"absolute\"\n",
        "custom_part_config1[\"input_ref_frame\"] = \"base\"\n",
        "custom_part_config1[\"gripper\"] = {'type':'GRIP'}\n",
        "custom_part_config1['control_freq']=20\n",
        "\n",
        "custom_part_config2 = load_part_controller_config(default_controller = \"JOINT_POSITION\")\n",
        "custom_part_config2[\"input_type\"] = \"absolute\"\n",
        "custom_part_config2[\"input_ref_frame\"] = \"base\"\n",
        "custom_part_config2[\"gripper\"] = {'type':'GRIP'}\n",
        "custom_part_config2['control_freq']=20\n",
        "\n",
        "controller_config = load_composite_controller_config(controller=\"BASIC\")\n",
        "controller_config['body_parts'] = {'right': custom_part_config1, 'left': custom_part_config2}\n",
        "print(controller_config.keys())\n",
        "controller_config['control_freq']=20\n",
        "\n",
        "dummy_spec = dict(\n",
        "    obs=dict(\n",
        "        low_dim=[],\n",
        "        rgb=[],\n",
        "    ),\n",
        ")\n",
        "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)\n",
        "\n",
        "env = Free(robots=[\"Baxter\"], controller_configs=controller_config)"
      ],
      "metadata": {
        "id": "HcBdIhDveXWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Demonstration Dataset"
      ],
      "metadata": {
        "id": "5MnXzxNla0JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download a pouring motion demo from the MIME dataset. (you can download other demo. if you want.)"
      ],
      "metadata": {
        "id": "WWCvMs2ra4V4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data():\n",
        "    \"\"\"\n",
        "    Extract a pouring motion demo from the MIME dataset. (you can download other demo. if you want.)\n",
        "    \"\"\"\n",
        "    cur_dir = os.getcwd().split('/')[-1]\n",
        "    assert cur_dir=='content', \"Run the program on the assignment_1 folder. Current directory is {}\".format(cur_dir)\n",
        "\n",
        "    if os.path.isdir('dataset') is False:\n",
        "        os.mkdir('dataset')\n",
        "    os.chdir( 'dataset' )\n",
        "\n",
        "    url = 'https://www.dropbox.com/sh/wmyek0jhrpm0hmh/AADAO2L1qN5BwOBthyMG82ima/4315Aug02?dl=0.zip'\n",
        "    if os.path.isfile(url.split('/')[-1]) is False:\n",
        "        os.system('wget '+url)\n",
        "\n",
        "    if os.path.isfile('joint_angles.txt') is False:\n",
        "        os.system('unzip 4315Aug02?dl=0.zip')\n",
        "\n",
        "    print (os.getcwd())\n",
        "\n",
        "    data = []\n",
        "    for line in open('joint_angles.txt', 'r'):\n",
        "        data.append( json.loads(line))\n",
        "\n",
        "    # Get left/right arm trajectories\n",
        "    joint_names = ['s0', 's1', 'e0', 'e1', 'w0', 'w1', 'w2']\n",
        "\n",
        "    l_arm_traj = []\n",
        "    r_arm_traj = []\n",
        "    for d in data:\n",
        "        v = []\n",
        "        for name in joint_names:\n",
        "            v.append(d['left_'+name])\n",
        "        l_arm_traj.append(v)\n",
        "\n",
        "        v = []\n",
        "        for name in joint_names:\n",
        "            v.append(d['right_'+name])\n",
        "        r_arm_traj.append(v)\n",
        "\n",
        "    os.chdir( '..' )\n",
        "    return np.swapaxes(r_arm_traj, 0, 1)"
      ],
      "metadata": {
        "id": "7XD_wjFybDE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also provide an auxiliary visualization function to compare demonstrated and reproduced trajectories."
      ],
      "metadata": {
        "id": "tuU2pXGsyLJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_traj(trajs, trajs_demo=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for i, traj in enumerate(trajs):\n",
        "        fig.add_subplot(len(trajs), 1, i+1)\n",
        "        plt.plot(traj, label=str(i))\n",
        "\n",
        "        if trajs_demo is not None:\n",
        "            if len(np.shape(trajs_demo))==2:\n",
        "                plt.plot(trajs_demo[i], 'r-', label=str(i))\n",
        "            else:\n",
        "                plt.plot(trajs_demo[0][i], 'r-', label=str(i))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VTvAL8m-bJhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Train improved DMPs with Joint-Space Demonstration."
      ],
      "metadata": {
        "id": "5bjUeXAKeMj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this sub-problem, we will re-use the improved Dynamic Movement Primitives (DMPs) to learn and reproduce a robot demonstration trajectory in joint space."
      ],
      "metadata": {
        "id": "Crz9Sx6Xeb5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1 Improved DMP Formulation"
      ],
      "metadata": {
        "id": "kApkrYJmsfC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s formulate the improved DMP equations:\n",
        "\n",
        "- **Canonical System:**  \n",
        "  <div align=\"center\">\n",
        "  $\n",
        "  \\tau \\dot{s} = -\\alpha s\n",
        "  $\n",
        "  </div>\n",
        "\n",
        "- **Nonlinear Function:**  \n",
        "  <div align=\"center\">\n",
        "  $\n",
        "  f(s) = \\frac{\\sum_i w_i \\, \\phi_i(s)\\, s}{\\sum_i \\phi_i(s)}\n",
        "  $\n",
        "  </div>  \n",
        "\n",
        "- **Transformation System:**  \n",
        "  <div align=\"center\">\n",
        "  $\n",
        "  \\tau \\dot{v} = K(g - x) - Dv + K(g - x_0)s + Kf, \\quad \\tau \\dot{x} = v\n",
        "  $\n",
        "  </div>\n",
        "  \n",
        "Based on these equations, please complete the code blocks below to implement the improved DMP formulation. Note that you can copy the code for the improved DMP's transformation system and DMP class code."
      ],
      "metadata": {
        "id": "_EzXKyb_dkkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OriginalFormulation(object):\n",
        "\n",
        "    def __init__(self, K=50., D=None):\n",
        "        self.K = K\n",
        "        if D is None:\n",
        "            D = 2.0 * np.sqrt(self.K)\n",
        "        self.D = D\n",
        "\n",
        "    def acceleration(self, x, dx, start, goal, tau, f, s):\n",
        "        ''' return acceleration '''\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        return\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "    def fs(self, x, dx, ddx, start, goal, tau, s):\n",
        "        ''' return nonlinear function value '''\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        return\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "class ImprovedFormulation(object):\n",
        "\n",
        "    def __init__(self, K=50., D=None):\n",
        "        self.K = K\n",
        "        if D is None:\n",
        "            D = self.K/4.\n",
        "        self.D = D\n",
        "\n",
        "    def acceleration(self, x, dx, start, goal, tau, f, s):\n",
        "        ''' return acceleration '''\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        return\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "    def fs(self, x, dx, ddx, start, goal, tau, s):\n",
        "        ''' return nonlinear function value '''\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        return\n",
        "        #------------------------------------------------------------"
      ],
      "metadata": {
        "id": "BDasrLp9eCmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DMPs_discrete(object):\n",
        "\n",
        "    def __init__(self, dims, bfs, dt=.01, tau=1., alpha=14, enable_improved=False, **kwargs):\n",
        "        '''\n",
        "        dims int: number of dynamic motor primitives\n",
        "        bfs int: number of basis functions per DMP\n",
        "        dt float: timestep for simulation\n",
        "        tau float: scales the timestep\n",
        "                   increase tau to make the system execute faster\n",
        "        alpha float: canonical system parameter\n",
        "        '''\n",
        "\n",
        "        self.dmps = dims\n",
        "        self.bfs  = bfs\n",
        "        self.dt   = dt\n",
        "        self.tau  = tau\n",
        "        self.alpha = alpha/2.0\n",
        "        self.alpha_x = alpha\n",
        "\n",
        "        self.prep_centers_and_variances()\n",
        "\n",
        "        if enable_improved is False:\n",
        "            self.formulation = OriginalFormulation()\n",
        "        else:\n",
        "            self.formulation = ImprovedFormulation()\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def prep_centers_and_variances(self):\n",
        "        '''\n",
        "        Set the centre of the Gaussian basis functions be spaced evenly\n",
        "        throughout run time.\n",
        "        '''\n",
        "        self.c = np.zeros(self.bfs)\n",
        "        self.h = np.zeros(self.bfs)\n",
        "\n",
        "        t = np.linspace(0,1,self.bfs) *0.5\n",
        "\n",
        "        # From DMP matlab code\n",
        "        self.c = np.exp(-self.alpha_x*t)\n",
        "        self.D = (np.diff(self.c)*0.55)**2\n",
        "        self.D = np.append(self.D, self.D[-1])\n",
        "        self.D = 1/self.D\n",
        "        self.h = np.ones(self.bfs)*0.5\n",
        "\n",
        "\n",
        "    def gen_psi(self, x):\n",
        "        '''\n",
        "        Generates the activity of the basis functions for a given state of the\n",
        "        canonical system.\n",
        "\n",
        "        x float: the current state of the canonical system\n",
        "        '''\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = x[:,None]\n",
        "        return np.exp(-self.h * (x - self.c)**2 * self.D)\n",
        "\n",
        "\n",
        "    def gen_phase(self, n_steps, tau=None):\n",
        "        \"\"\"\n",
        "        Generate phase for open loop movements.\n",
        "\n",
        "        n_steps int: number of steps\n",
        "        \"\"\"\n",
        "        if tau is None: tau = self.tau\n",
        "        return np.exp(-self.alpha/tau * np.linspace(0, 1, n_steps))\n",
        "\n",
        "\n",
        "    def learn(self, y_des):\n",
        "        \"\"\"\n",
        "        Encode a set of weights from the input trajectories.\n",
        "\n",
        "        y_des list/array: the desired trajectories of each DMP\n",
        "                          should be shaped [dmps, run_time]\n",
        "        \"\"\"\n",
        "        # Set variables\n",
        "        n_samples, dims, n_steps = np.shape(y_des)\n",
        "        self.n_steps = n_steps\n",
        "        assert dims==self.dmps, \"wrong dimensions\"\n",
        "\n",
        "        # Get start and goal\n",
        "        self.y0   = np.mean(y_des[:,:,0], axis=0)\n",
        "        self.goal = np.mean(y_des[:,:,-1], axis=0)\n",
        "\n",
        "        # Calculate yd_des, ydd_des\n",
        "        yd_des = np.diff(y_des) / self.dt\n",
        "        yd_des = np.concatenate((np.zeros((n_samples, self.dmps, 1)), yd_des), axis=2)\n",
        "\n",
        "        ydd_des = np.diff(yd_des) / self.dt\n",
        "        ydd_des = np.concatenate((np.zeros((n_samples, self.dmps, 1)), ydd_des), axis=2)\n",
        "\n",
        "        # Get a canonical system\n",
        "        x_track = self.gen_phase(n_steps)\n",
        "\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "\n",
        "        # Calculate f\n",
        "        f_des =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Calculate weights\n",
        "        psi_track =\n",
        "\n",
        "        x_track   =\n",
        "        psi_track =\n",
        "        f_des     =\n",
        "        f_des     =\n",
        "\n",
        "        self.w =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "        # set up tracking vectors\n",
        "        y_track   = np.zeros((self.dmps, n_steps))\n",
        "        yd_track  = np.zeros((self.dmps, n_steps))\n",
        "        ydd_track = np.zeros((self.dmps, n_steps))\n",
        "\n",
        "        y   = self.y0.copy()\n",
        "        yd  = np.zeros(self.dmps)\n",
        "        ydd = np.zeros(self.dmps)\n",
        "\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        x_track   =\n",
        "        psi_track =\n",
        "\n",
        "        f =\n",
        "\n",
        "\n",
        "\n",
        "        # Recover the demonstration using the learned weights (for confirmation)\n",
        "        for t in range(n_steps):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # record timestep\n",
        "            y_track[:,t] =\n",
        "            yd_track[:,t] =\n",
        "            ydd_track[:,t] =\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "        return y_track, yd_track, ydd_track\n",
        "\n",
        "\n",
        "    def plan(self, y0=None, goal=None, **kwargs):\n",
        "        '''\n",
        "        Run the DMP system within a specific period.\n",
        "\n",
        "        y0   list/array: start position\n",
        "        goal list/array: goal position\n",
        "        tau  float:      scales the timestep\n",
        "                         increase tau to make the system execute faster\n",
        "        '''\n",
        "\n",
        "        if y0 is None: y0 = self.y0\n",
        "        if goal is None: goal = self.goal\n",
        "        n_steps = int(self.n_steps/self.tau)\n",
        "\n",
        "        # set up tracking vectors\n",
        "        y_track   = np.zeros((self.dmps, n_steps))\n",
        "        yd_track  = np.zeros((self.dmps, n_steps))\n",
        "        ydd_track = np.zeros((self.dmps, n_steps))\n",
        "        x_track   = self.gen_phase(n_steps, self.tau)\n",
        "\n",
        "        #------------------------------------------------------------\n",
        "        # Place your code here\n",
        "        y   =\n",
        "        yd  =\n",
        "        ydd =\n",
        "\n",
        "        for t in range(n_steps):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # record timestep\n",
        "            y_track[:,t] =\n",
        "            yd_track[:,t] =\n",
        "            ydd_track[:,t] =\n",
        "        #------------------------------------------------------------\n",
        "\n",
        "        return y_track, yd_track, ydd_track\n",
        "\n",
        "\n",
        "    def plot_traj(self, trajs_demo, trajs_gen, axis_num=0):\n",
        "        \"\"\"Plot trajectories over an axis \"\"\"\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.title('Trajectory (X) - Demo (Td) and generated (Tg)')\n",
        "        for i in range(len(trajs_demo)):\n",
        "            plt.plot(trajs_demo[i,axis_num,:], 'r--', label='Td')\n",
        "        for i in range(len(trajs_gen)):\n",
        "            plt.plot(trajs_gen[i,axis_num,:],'g-', label='Tg')\n",
        "\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_basis(self):\n",
        "        \"\"\"Plot basis functions \"\"\"\n",
        "        fig = plt.figure()\n",
        "\n",
        "        x = self.gen_phase(200)\n",
        "\n",
        "        for idx in range(len(self.c)):\n",
        "            psi = self.gen_psi(x)\n",
        "            plt.plot(x, psi)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def plot_f(self, f, f_des=None):\n",
        "        \"\"\"Plot nonlinear functions \"\"\"\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.plot(f)\n",
        "        if f_des is not None:\n",
        "            plt.plot(f_des, '--')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_canonical_sys(self):\n",
        "        \"\"\"Plot the phase change in the canonical system \"\"\"\n",
        "        x = self.gen_phase(200)\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.plot(x)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "PlAoZgbVeT-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.2 Training and Reproduction of Joint-Space Demonstration"
      ],
      "metadata": {
        "id": "YFAOlNbGxvuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the improved DMPs with the selected joint-space demonstration trajectory. Please, plot the reproduced trajectories with the demonstrated trajectory with the same goal and start."
      ],
      "metadata": {
        "id": "SySZBmiFdosg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def problem_3a1(enable_plot=True):\n",
        "    traj = extract_data()\n",
        "\n",
        "    dims      = len(traj)\n",
        "    bfs       = 30\n",
        "    tau       = 1.\n",
        "    freq      = 100\n",
        "    duration  = 1.\n",
        "    dt        = 1./freq\n",
        "\n",
        "    traj_demo = np.expand_dims(traj, axis=0)\n",
        "\n",
        "    # Learn via DMP original/improved\n",
        "    dmp = DMPs_discrete(dims=dims, bfs=bfs, tau=tau, dt=dt,\n",
        "                            enable_improved=True)\n",
        "    traj, _, _ = dmp.learn(traj_demo)\n",
        "    traj, _, _ = dmp.plan()\n",
        "\n",
        "    if enable_plot: plot_traj(traj, traj_demo)\n",
        "    return traj\n"
      ],
      "metadata": {
        "id": "LuMeXO4RczQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's confirm if our DMP could reproduce the demonstrated trajectory."
      ],
      "metadata": {
        "id": "BHHRKmIxwU1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_traj_data = problem_3a1(enable_plot=True)"
      ],
      "metadata": {
        "id": "XjO1-eSNj-Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  A.3 Reproduction on the Baxter robot"
      ],
      "metadata": {
        "id": "IPcKyz7jdX0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's enable the simulated Baxter robot to track the reproduced trajectory."
      ],
      "metadata": {
        "id": "QvyjdD8KzH3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"MUJOCO_GL\"] = 'osmesa'\n",
        "\n",
        "# create a video writer\n",
        "video_path = \"rollout_A.mp4\"\n",
        "video_writer = imageio.get_writer(video_path, fps=20)\n",
        "\n",
        "ob_dict = env.reset()\n",
        "init_joint_pos = ob_dict[\"robot0_joint_pos\"]\n",
        "\n",
        "# initialize the starting configuration\n",
        "for i in range(200):\n",
        "  action = np.concatenate([r_traj_data[:,0], init_joint_pos[7:], np.zeros(2)], axis=-1)\n",
        "  ob_dict, _, _, _ = env.step(action)\n",
        "\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Place your code here\n",
        "\n",
        "# follow the reproduced trajectory\n",
        "traj = []\n",
        "traj_des = []\n",
        "for i in range(1,len(r_traj_data[0]),5): # 20Hz\n",
        "    action =\n",
        "    ob_dict, _, _, _ = env.step(action)\n",
        "\n",
        "    cur_joint_pos = ob_dict[\"robot0_joint_pos\"]\n",
        "    traj.append(cur_joint_pos[:7])\n",
        "    traj_des.append(r_traj_data[:,i])\n",
        "\n",
        "    frame = env.sim.render(height=512, width=512, camera_name=\"frontview\")[::-1]\n",
        "    video_writer.append_data(frame)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "\n",
        "video_writer.close()"
      ],
      "metadata": {
        "id": "NOsqZkpnecSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the desired and simulated robot trajectories."
      ],
      "metadata": {
        "id": "bUokaP5W39bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_traj(np.array(traj).T, np.array(traj_des).T)"
      ],
      "metadata": {
        "id": "stz3M7rZrZUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visulize the simulated robot's rollout video."
      ],
      "metadata": {
        "id": "2xAqpQFRzesJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize rollout video\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "wPlPqsiZef4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Train improved DMPs with Cartesian-Space Demonstration."
      ],
      "metadata": {
        "id": "jh9Uz8Bk4GYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, in this sub-problem, we train the improved DMP using a Cartesian-space demonstration and reproduce the motion using a Baxter robot."
      ],
      "metadata": {
        "id": "nzD_Lo4WwCY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.1 Robot Kinematics Class Construction"
      ],
      "metadata": {
        "id": "8lzwYIc01pBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define an auxiliary class to perform forward and inverse kinematics."
      ],
      "metadata": {
        "id": "LMRewE5z0hLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from robosuite.utils.transform_utils import mat2quat, quat2mat  # robosuite: xyzw\n",
        "import mujoco as mj\n",
        "\n",
        "class robot_kinematics(object):\n",
        "    def __init__(self, env, arm='right'):\n",
        "        self.env = env\n",
        "        self.arm = arm\n",
        "        self.robot = env.robots[0]\n",
        "\n",
        "        if arm == 'right':\n",
        "            self.qpos_idx = self.robot._ref_joint_pos_indexes[:7]\n",
        "        else:\n",
        "            self.qpos_idx = self.robot._ref_joint_pos_indexes[7:]\n",
        "\n",
        "        self.eef_sid = self.robot.eef_site_id[arm] if isinstance(self.robot.eef_site_id, dict) else self.robot.eef_site_id\n",
        "        self.ndof = len(self.qpos_idx)\n",
        "\n",
        "        # Find the base body id\n",
        "        first_qi = int(self.qpos_idx[0])\n",
        "        jids = np.where(env.sim.model.jnt_qposadr == first_qi)[0]\n",
        "        first_jid = int(jids[0])\n",
        "        self.base_body_id = int(env.sim.model.jnt_bodyid[first_jid])\n",
        "\n",
        "        # Find the joint limits\n",
        "        self.joint_low, self.joint_high = self._joint_limits_from_qpos_idx()\n",
        "\n",
        "        m = self.env.sim.model\n",
        "        base_name = m.body_id2name(self.base_body_id)\n",
        "        eef_name  = m.site_id2name(self.eef_sid)\n",
        "        print(f\"[{self.arm}] base_body={base_name}, eef_site={eef_name}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _quat_mul_xyzw(q1, q2):\n",
        "        x1,y1,z1,w1 = q1; x2,y2,z2,w2 = q2\n",
        "        return np.array([\n",
        "            w1*x2 + x1*w2 + y1*z2 - z1*y2,\n",
        "            w1*y2 - x1*z2 + y1*w2 + z1*x2,\n",
        "            w1*z2 + x1*y2 - y1*x2 + z1*w2,\n",
        "            w1*w2 - x1*x2 - y1*y2 - z1*z2\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def _quat_inv_xyzw(q):\n",
        "        x,y,z,w = q\n",
        "        return np.array([-x, -y, -z, w])  # 단위쿼터니언 가정\n",
        "\n",
        "    @staticmethod\n",
        "    def _rotvec_from_quats_xyzw(q_now, q_tgt):\n",
        "        \"\"\"q_err = q_tgt * inv(q_now) → axis-angle (회전벡터)\"\"\"\n",
        "        q_err = robot_kinematics._quat_mul_xyzw(q_tgt, robot_kinematics._quat_inv_xyzw(q_now))\n",
        "        x,y,z,w = q_err\n",
        "        v = np.array([x,y,z], dtype=float)\n",
        "        n = np.linalg.norm(v)\n",
        "        if n < 1e-12:\n",
        "            return np.zeros(3)\n",
        "        axis = v / n\n",
        "        angle = 2.0 * np.arctan2(n, w)\n",
        "        return axis * angle  # 3D 회전벡터\n",
        "\n",
        "    def get_arm_base_body_id(self, arm: str) -> int:\n",
        "        \"\"\" Find a base body id \"\"\"\n",
        "        m = self.env.sim.model\n",
        "        # 전역 joint name -> id 매핑\n",
        "        name_to_jid = {name: i for i, name in enumerate(m.joint_names)}\n",
        "        # 해당 팔의 관절명 목록에서 첫 관절의 body를 베이스로 사용\n",
        "        first_jn = self.robot.joint_names[arm][0]\n",
        "        jid = name_to_jid[first_jn]\n",
        "        return int(m.jnt_bodyid[jid])\n",
        "\n",
        "    def _joint_limits_from_qpos_idx(self):\n",
        "        \"\"\"각 qpos 인덱스에 대응하는 hinge/slide joint의 범위를 모아 반환\"\"\"\n",
        "        d, m = self.env.sim.data, self.env.sim.model\n",
        "\n",
        "        lows, highs = [], []\n",
        "        for qi in self.qpos_idx:\n",
        "            jids = np.where(m.jnt_qposadr == int(qi))[0]\n",
        "            assert len(jids) > 0, \"qpos→joint 매핑 실패\"\n",
        "            jid = int(jids[0])\n",
        "            lo, hi = m.jnt_range[jid]\n",
        "            if hi > lo:  # 유한 범위\n",
        "                lows.append(lo); highs.append(hi)\n",
        "            else:       # 무한(자유)처럼 정의 → 넓게 허용\n",
        "                lows.append(-1e9); highs.append(1e9)\n",
        "        return np.asarray(lows), np.asarray(highs)\n",
        "\n",
        "    def fk_request(self, q):\n",
        "        \"\"\" Foward Kinematics \"\"\"\n",
        "        d, m = self.env.sim.data, self.env.sim.model\n",
        "        d.qpos[self.qpos_idx] = q\n",
        "        d.qvel[...] = 0.0\n",
        "        self.env.sim.forward()\n",
        "\n",
        "        # World to EE\n",
        "        p_w = d.site_xpos[self.eef_sid].copy()\n",
        "        R_w = d.site_xmat[self.eef_sid].reshape(3,3).copy()\n",
        "        q_w = mat2quat(R_w)  # (x,y,z,w)\n",
        "        return p_w, q_w\n",
        "\n",
        "        # World to Base\n",
        "        #p_bw = d.xpos[self.base_body_id].copy()\n",
        "        #R_bw = d.xmat[self.base_body_id].reshape(3,3).copy()\n",
        "\n",
        "        # Base to EE\n",
        "        #R_rel = R_bw.T @ R_w\n",
        "        #p_rel = R_bw.T @ (p_w - p_bw)\n",
        "        #q_rel = mat2quat(R_rel)\n",
        "\n",
        "        #return p_rel, q_rel\n",
        "\n",
        "    def ik_request(\n",
        "        self,\n",
        "        target_pos,                  # (3,) in world frame\n",
        "        target_quat=None,            # (4,) xyzw in world frame; if None -> position-only IK\n",
        "        q_init=None,               # 초기 관절값(ndof,) 없으면 현재 값을 사용\n",
        "        max_iters=200,\n",
        "        pos_tol=1e-4,\n",
        "        ori_tol=1e-3,                # radians\n",
        "        pos_w=1.0,\n",
        "        ori_w=1.0,\n",
        "        damping=1e-3,\n",
        "        step_size=1.0,\n",
        "        enforce_limits=True,\n",
        "    ):\n",
        "        \"\"\" Inverse Kinematics \"\"\"\n",
        "        d, m = self.env.sim.data, self.env.sim.model\n",
        "\n",
        "        # initial configuration for jacobian\n",
        "        if q_init is None:\n",
        "            q_arm = d.qpos[self.qpos_idx].copy()\n",
        "        else:\n",
        "            q_arm = np.asarray(q_init, dtype=float).copy()\n",
        "            assert q_arm.shape == (self.ndof,)\n",
        "\n",
        "\n",
        "        # 조인트 제한\n",
        "        if enforce_limits:\n",
        "            joint_low, joint_high = self.joint_low, self.joint_high\n",
        "        else:\n",
        "            joint_low = np.full(self.ndof, -1e9); joint_high = np.full(self.ndof, 1e9)\n",
        "\n",
        "        # 자코비안 버퍼 (MuJoCo 요구 스펙: float64, C-order, (3, nv))\n",
        "        Jp = np.zeros((3, m.nv), dtype=np.float64, order=\"C\")\n",
        "        Jr = np.zeros((3, m.nv), dtype=np.float64, order=\"C\")\n",
        "\n",
        "        # robosuite 래퍼면 원본으로 언랩\n",
        "        if hasattr(m, \"_model\"): mjm = m._model\n",
        "        else: mjm = m\n",
        "        if hasattr(d, \"_data\"):  mjd = d._data\n",
        "        else: mjd = d\n",
        "\n",
        "        for _ in range(max_iters):\n",
        "            # 시뮬레이터 상태 반영\n",
        "            d.qpos[self.qpos_idx] = q_arm\n",
        "            d.qvel[self.qpos_idx] = 0.0\n",
        "            self.env.sim.forward()\n",
        "\n",
        "            # 현재 EEF 포즈\n",
        "            p_now = d.site_xpos[self.eef_sid].copy()\n",
        "            R_now = d.site_xmat[self.eef_sid].reshape(3,3).copy()\n",
        "            q_now = mat2quat(R_now)  # xyzw\n",
        "\n",
        "            # 오차\n",
        "            dp = target_pos - p_now\n",
        "            if target_quat is None:\n",
        "                e = pos_w * dp                                # (3,)\n",
        "                mj.mj_jacSite(mjm, mjd, Jp, None, self.eef_sid)\n",
        "                J = pos_w * Jp[:, self.qpos_idx]                   # (3, ndof)\n",
        "            else:\n",
        "                drot = robot_kinematics._rotvec_from_quats_xyzw(q_now, target_quat)   # (3,)\n",
        "                e = np.hstack([pos_w * dp, ori_w * drot])            # (6,)\n",
        "                mj.mj_jacSite(mjm, mjd, Jp, Jr, self.eef_sid)\n",
        "                J = np.vstack([pos_w * Jp[:, self.qpos_idx], ori_w * Jr[:, self.qpos_idx]])  # (6, ndof)\n",
        "\n",
        "            # 수렴 체크\n",
        "            pos_err = np.linalg.norm(dp)\n",
        "            ori_err = 0.0 if target_quat is None else np.linalg.norm(drot)\n",
        "            if (pos_err < pos_tol) and (target_quat is None or ori_err < ori_tol):\n",
        "                return q_arm.copy(), True\n",
        "\n",
        "            # DLS: dq = (J^T J + λ^2 I)^-1 J^T e\n",
        "            JT = J.T\n",
        "            H  = JT @ J + (damping**2) * np.eye(self.ndof)\n",
        "            g  = JT @ e\n",
        "            dq = np.linalg.solve(H, g)\n",
        "\n",
        "            # 업데이트 + 제한\n",
        "            q_arm = np.clip(q_arm + step_size * dq, joint_low, joint_high)\n",
        "\n",
        "        return q_arm.copy(), False"
      ],
      "metadata": {
        "id": "2BbHSdnaDBXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.2 Training and Reproduction of Cartesian-Space Demonstration"
      ],
      "metadata": {
        "id": "QtFaw-P814A6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the improved DMPs with the selected joint-space demonstration trajectory. Please, plot the reproduced trajectories with the demonstrated trajectory with the same goal and start."
      ],
      "metadata": {
        "id": "XlLVv0Jh1n1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def problem_3bc(env, arm='right', goal=None, video_path=\"rollout.mp4\"):\n",
        "    \"\"\"\n",
        "    Check if you want better orientation-based DMP:\n",
        "    Ude et al. Orientation in cartesian space dynamic movement primitives. In IEEE International Conference on Robotics and Automation (ICRA), 2014.\n",
        "    \"\"\"\n",
        "    dims      = 7\n",
        "    bfs       = 30\n",
        "    tau       = 1.\n",
        "    freq      = 100\n",
        "    duration  = 1.\n",
        "    dt        = 1./freq\n",
        "    sample_scale = 20\n",
        "    r_traj_data  = extract_data()\n",
        "\n",
        "    # FK, IK solvers for Baxter\n",
        "    rk = robot_kinematics(env, arm=arm)\n",
        "\n",
        "    #------------------------------------------------------------\n",
        "    # Place your code here\n",
        "    # make a list of x,y,z,qx,qy,qz,qw\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    pose_list =\n",
        "    pose_traj_demo =\n",
        "    #------------------------------------------------------------\n",
        "\n",
        "    # Learn via DMP original/improved\n",
        "    dmp = DMPs_discrete(dims=dims, bfs=bfs, tau=tau, dt=dt,\n",
        "                            enable_improved=True)\n",
        "    _, _, _ = dmp.learn( pose_traj_demo ) #[:,:6,:] )\n",
        "\n",
        "    # setting a goal\n",
        "    pose_traj, _, _ = dmp.plan(goal=goal)\n",
        "\n",
        "    # normalize the quaternions\n",
        "    pose_traj[3:] /= np.sum( pose_traj[3:]**2, axis=0)\n",
        "\n",
        "    # conver the pos+quaternion trajectory to pose list\n",
        "    pose_list = []\n",
        "    for i in range(len(pose_traj[0])):\n",
        "        # reduce the number of samples (OPTION)\n",
        "        if i%sample_scale==0:\n",
        "            pose_list.append( pose_traj[:,i] )\n",
        "\n",
        "    # Command Current Joint Positions first\n",
        "    # create a video writer\n",
        "    video_writer = imageio.get_writer(video_path, fps=20)\n",
        "\n",
        "    ob_dict = env.reset()\n",
        "\n",
        "    # initialize the starting configuration\n",
        "    env.sim.data.qpos[rk.qpos_idx] = r_traj_data[:,0]\n",
        "    env.sim.data.qvel[rk.qpos_idx] = 0.0\n",
        "    env.sim.forward()\n",
        "\n",
        "    #------------------------------------------------------------\n",
        "    # Place your code here\n",
        "\n",
        "    # follow the reproduced trajectory\n",
        "    init_joint_pos = ob_dict[\"robot0_joint_pos\"].copy()\n",
        "    traj = []\n",
        "    traj_des = []\n",
        "\n",
        "    for i in range(1,len(pose_traj[0]),20): # 5Hz\n",
        "        q_ret\n",
        "\n",
        "        action =\n",
        "        ob_dict, _, _, _ = env.step(action)\n",
        "\n",
        "        cur_joint_pos = ob_dict[\"robot0_joint_pos\"][:7]\n",
        "        traj.append(cur_joint_pos)\n",
        "        traj_des.append(q_ret)\n",
        "\n",
        "        frame = env.sim.render(height=512, width=512, camera_name=\"frontview\")[::-1]\n",
        "        video_writer.append_data(frame)\n",
        "    #------------------------------------------------------------\n",
        "\n",
        "    video_writer.close()\n",
        "\n",
        "    return pose_traj, pose_traj_demo"
      ],
      "metadata": {
        "id": "g6o6yBH8k3KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"rollout_B.mp4\"\n",
        "\n",
        "pose_traj, pose_traj_demo = problem_3bc(env, video_path=video_path)"
      ],
      "metadata": {
        "id": "lO7AwaU5k4hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B.3 Reproduction on the Baxter robot"
      ],
      "metadata": {
        "id": "FWIqnbHo2HMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the simulated Baxter robot to track the reproduced trajectory."
      ],
      "metadata": {
        "id": "rWGJypI0rUIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize rollout video\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "CeNz4jZ5rMCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now check if the robot was able to track the reproduced trajectory."
      ],
      "metadata": {
        "id": "2sRzXEMa151r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_traj(pose_traj, pose_traj_demo)"
      ],
      "metadata": {
        "id": "6hZYwUvcml44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Adapt the learned DMPs with different goals."
      ],
      "metadata": {
        "id": "w8I5HDO04SVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.1 Training and Reproduction of Cartesian-Space Demonstration"
      ],
      "metadata": {
        "id": "mRd-rb-U2eeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We provide a new goal to show the adapation performance of the improved DMPs."
      ],
      "metadata": {
        "id": "oUeJqOwB2dt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"rollout_C.mp4\"\n",
        "\n",
        "rk = robot_kinematics(env, arm='right')\n",
        "pos, quat = rk.fk_request(r_traj_data[:,-1])\n",
        "pos[1] += 0.1\n",
        "goal = np.concatenate([pos, quat])\n",
        "print(\"New goal:\", goal)\n",
        "\n",
        "pose_traj, pose_traj_demo = problem_3bc(env, goal=goal, video_path=video_path)"
      ],
      "metadata": {
        "id": "N9MX0XS0rqQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.2 Reproduction on the Baxter robot"
      ],
      "metadata": {
        "id": "jUMoJ7o72ZbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the simulated Baxter robot to track the reproduced trajectory."
      ],
      "metadata": {
        "id": "FG75KyDv36J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize rollout video\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "rvbeXI24u8d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now check if the robot was able to track the reproduced trajectory."
      ],
      "metadata": {
        "id": "7b-Df6XW3-pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_traj(pose_traj, pose_traj_demo)"
      ],
      "metadata": {
        "id": "o3FOnRRhu97o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you can try the same thing for the original formulation of DMPs below."
      ],
      "metadata": {
        "id": "PbW3-XYxgTMh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4U5mmu2SgZH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}